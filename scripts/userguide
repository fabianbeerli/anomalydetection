# Subsequence Analysis Framework - Usage Guide

This guide explains how to use the enhanced subsequence analysis framework for your bachelor thesis on anomaly detection in S&P 500 data.

## Overview of Scripts

The framework consists of the following scripts:

1. **run_subsequence_algorithms.py**: Core script for running anomaly detection algorithms on a specific subsequence configuration.
2. **run_multiple_configs.py**: Script to run multiple subsequence configurations (window sizes, overlap/non-overlap) in sequence.
3. **compare_subsequence_results.py**: Script to compare and visualize results from different subsequence configurations.
4. **run-subsequence-analysis.sh/bat**: Shell scripts for easy execution on Unix-like systems (Linux/macOS) or Windows.

## Prerequisites

Before running these scripts, ensure you have:

1. All required Python packages installed (`pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`)
2. For AIDA (C++): A C++ compiler (g++) and OpenMP support
3. Preprocessed data with both overlapping and non-overlapping subsequences (generated by your data preparation script)

## Basic Usage

### Option 1: Using the Shell Scripts (Recommended)

For Unix-like systems (Linux/macOS):
```bash
./run-subsequence-analysis.sh
```

For Windows:
```
run-subsequence-analysis.bat
```

These scripts use default parameters. You can customize them as follows:

```bash
./run-subsequence-analysis.sh --window-sizes "3 5 10" --overlap-mode all --algorithms all
```

Parameters:
- `--subsequence-dir`: Directory containing subsequence data
- `--output-dir`: Directory to save algorithm results
- `--algorithms`: Algorithms to run (all, aida, iforest, lof)
- `--window-sizes`: Window sizes to run (space-separated)
- `--overlap-mode`: Overlap mode (all, overlap, nonoverlap)
- `--no-comparison`: Skip running the comparison script

### Option 2: Using Python Scripts Directly

#### Step 1: Run a Single Configuration

```bash
python run_subsequence_algorithms.py --window-size 3 --overlap --algorithms all
```

Parameters:
- `--subsequence-dir`: Directory containing subsequence data
- `--window-size`: Size of subsequence window
- `--overlap`: Use overlapping subsequences
- `--no-overlap`: Use non-overlapping subsequences (mutually exclusive with --overlap)
- `--output`: Directory to save algorithm results
- `--algorithms`: Algorithms to run (aida, iforest, lof, all)

#### Step 2: Run Multiple Configurations

```bash
python run_multiple_configs.py --window-sizes 3 5 10 --all-overlaps --run-comparison
```

Parameters:
- `--subsequence-dir`: Directory containing subsequence data
- `--window-sizes`: Window sizes to run (space-separated)
- `--all-overlaps`: Run both overlapping and non-overlapping versions
- `--only-overlap`: Only run overlapping versions
- `--only-non-overlap`: Only run non-overlapping versions
- `--output`: Directory to save algorithm results
- `--algorithms`: Algorithms to run (aida, iforest, lof, all)
- `--run-comparison`: Run comparison script after all configurations complete

#### Step 3: Compare Results

```bash
python compare_subsequence_results.py --configs w3_overlap w3_nonoverlap
```

Parameters:
- `--results-dir`: Directory containing algorithm results
- `--configs`: Configurations to compare (e.g., w3_overlap, w5_nonoverlap)
- `--data`: Path to the original S&P 500 data
- `--output`: Directory to save comparison results

## Directory Structure

The framework expects and creates the following directory structure:

```
project/
├── data/
│   ├── processed/
│   │   ├── subsequences/      # Generated subsequence data
│   │   └── index_GSPC_processed.csv  # Processed S&P 500 data
│   ├── subsequence_results/   # Analysis results by configuration
│   │   ├── aida/
│   │   │   ├── w3_overlap/
│   │   │   ├── w3_nonoverlap/
│   │   │   └── ...
│   │   ├── iforest/
│   │   │   └── ...
│   │   └── lof/
│   │       └── ...
│   └── subsequence_comparison/  # Comparison visualizations
├── scripts/
│   ├── run_subsequence_algorithms.py
│   ├── run_multiple_configs.py
│   ├── compare_subsequence_results.py
│   ├── run-subsequence-analysis.sh
│   └── run-subsequence-analysis.bat
└── src/
    └── ...
```

## Example Workflows

### Workflow 1: Analyze Standard Configurations

To run the default analysis with 3-day and 5-day windows, both overlapping and non-overlapping:

```bash
./run-subsequence-analysis.sh
```

This will:
1. Run all algorithms on 3-day overlapping subsequences
2. Run all algorithms on 3-day non-overlapping subsequences
3. Run all algorithms on 5-day overlapping subsequences
4. Run all algorithms on 5-day non-overlapping subsequences
5. Generate comparison visualizations

### Workflow 2: Analyze Specific Window Size

To focus on only 3-day subsequences, both overlapping and non-overlapping:

```bash
./run-subsequence-analysis.sh --window-sizes "3" --overlap-mode all
```

### Workflow 3: Compare Different Algorithms on Same Configuration

To compare only specific algorithms on 5-day overlapping windows:

```bash
./run-subsequence-analysis.sh --window-sizes "5" --overlap-mode overlap --algorithms "aida iforest"
```

## Interpreting Results

The comparison results include:

1. **Execution Time Comparison**: Bar charts comparing execution times across algorithms and configurations
2. **Anomaly Count Comparison**: Bar charts showing number of anomalies detected by each algorithm in each configuration
3. **Anomaly Visualizations**: Time series plots showing detected anomalies for each configuration
4. **Anomaly Timeline**: Visual timeline of when anomalies were detected across configurations
5. **Anomaly Overlap Analysis**: Comparison of how much anomalies overlap between different configurations

These visualizations will help you analyze:
- Which algorithm is most efficient for different subsequence types
- How the window size and overlap/non-overlap setting affects detection sensitivity
- Whether certain market periods consistently show anomalies across different methods
- Which configuration provides the most meaningful anomaly detection results

## Extending the Framework

If you need to extend this framework, consider:

1. Adding new algorithms by modifying `run_subsequence_algorithms.py`
2. Adding additional metrics or visualizations to `compare_subsequence_results.py`
3. Extending the framework to analyze multi-scale detection by combining results from different window sizes

## Troubleshooting

### AIDA Compilation Issues

If you encounter issues with AIDA compilation:

1. Check that you have a C++ compiler installed and in your PATH
2. For macOS users, ensure OpenMP is installed with `brew install libomp`
3. Check compiler error messages in the log output
4. Try running only the Python-based algorithms (iforest, lof) by specifying `--algorithms "iforest lof"`

### Missing Subsequence Files

If the script can't find subsequence files:

1. Check that your data preparation script has generated both overlapping and non-overlapping subsequences
2. Verify the naming convention: files should be named like `sp500_len3_overlap*.csv` and `sp500_len3_nonoverlap*.csv`
3. Confirm that the subsequence directory path is correct

### Other Common Issues

- If you see "No anomalies detected" warnings, try adjusting the contamination parameter in the algorithm classes
- For memory issues with large datasets, reduce the number of window sizes or run configurations individually
- For visualization problems, ensure matplotlib and seaborn are properly installed